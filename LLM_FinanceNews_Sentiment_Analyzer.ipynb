{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db63ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM_Finance_Sentiment_Analyzer.ipynb\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "def get_sentiment_analyzer(model_name=\"ProsusAI/finbert\"):\n",
    "    \"\"\"Initializes and returns a sentiment analysis pipeline.\"\"\"\n",
    "    return pipeline(\"sentiment-analysis\", model=model_name)\n",
    "\n",
    "def analyze_sentiment(text, analyzer, max_chars=512):\n",
    "    \"\"\"Runs sentiment analysis on a text split into chunks, averaging the results.\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    # Split text into chunks of max_chars\n",
    "    chunks = [text[i:i+max_chars] for i in range(0, len(text), max_chars)]\n",
    "    \n",
    "    # Collect results for all chunks\n",
    "    scores = {}\n",
    "    for chunk in chunks:\n",
    "        result = analyzer(chunk)[0]\n",
    "        label = result['label']\n",
    "        score = result['score']\n",
    "        \n",
    "        if label not in scores:\n",
    "            scores[label] = []\n",
    "        scores[label].append(score)\n",
    "    \n",
    "    # Compute average score per label\n",
    "    avg_scores = {label: sum(vals)/len(vals) for label, vals in scores.items()}\n",
    "    \n",
    "    # Pick label with highest average score\n",
    "    final_label = max(avg_scores, key=avg_scores.get)\n",
    "    \n",
    "    return {\n",
    "        \"label\": final_label,\n",
    "        \"confidence\": avg_scores[final_label],\n",
    "    }\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
