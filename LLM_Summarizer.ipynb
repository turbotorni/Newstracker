{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ecdbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM_Summarizer.ipynb\n",
    "\n",
    "import torch\n",
    "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
    "\n",
    "def get_summarizer(model_name=\"allenai/led-base-16384\"):\n",
    "    \"\"\"Initializes and returns LED summarizer components.\"\"\"\n",
    "    tokenizer = LEDTokenizer.from_pretrained(model_name)\n",
    "    model = LEDForConditionalGeneration.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "def summarize_with_led(text, tokenizer, model, max_input_tokens=4096, summary_max_len=250):\n",
    "    \"\"\"Generates a summary for a given text using LED.\"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_input_tokens\n",
    "    )\n",
    "\n",
    "    global_attention_mask = torch.zeros_like(inputs[\"input_ids\"])\n",
    "    global_attention_mask[:, 0] = 1\n",
    "\n",
    "    summary_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        global_attention_mask=global_attention_mask,\n",
    "        max_length=summary_max_len,\n",
    "        min_length=80,\n",
    "        num_beams=4,\n",
    "        length_penalty=2.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
